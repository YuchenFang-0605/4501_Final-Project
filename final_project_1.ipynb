{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a5c026",
   "metadata": {},
   "source": [
    "# Final Project - NYC Apartment Search - Group 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8272165",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a5841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ce7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"nzMxHq7vh4aj5sl0jx9gggdlP\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"resource/erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"resource/5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"NYC-Data\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"dddd\"  # Replace with your actual PostgreSQL password\n",
    "DB_URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@localhost:5433/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "DB_PORT = 5433\n",
    "\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f63ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66c522d",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f50b34",
   "metadata": {},
   "source": [
    "+ The following code defines functions to download data , clean and filtering for the relevant data, fill in missing data, and generate samples of these datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ddfdd6",
   "metadata": {},
   "source": [
    "### 1.1 Data downloading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8f1da9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pathlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DATA_DIR \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_nyc_geojson_data\u001b[39m(url, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m     parsed_url \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlparse(url)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pathlib' is not defined"
     ]
    }
   ],
   "source": [
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "\n",
    "def download_nyc_geojson_data(url, force=False):\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    url_path = parsed_url.path.strip(\"/\")\n",
    "    \n",
    "    filename = DATA_DIR / url_path\n",
    "    \n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "\n",
    "        response = requests.get(url)\n",
    "        geojson_data = response.json()\n",
    "\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(geojson_data, f, default=str)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    \n",
    "    \"\"\"\n",
    "    Load and clean zipcode data from a file.\n",
    "\n",
    "    Parameters:\n",
    "        zipcode_datafile (str): The file path to the zipcode data file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned DataFrame containing zipcode data.\n",
    "    \"\"\"\n",
    "    # Load the data from the file\n",
    "    df = gpd.read_file(zipcode_datafile)\n",
    "    \n",
    "    # To keep the necessary columns\n",
    "    df_selected = df\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    df_selected = df_selected.dropna()\n",
    "\n",
    "    # Convert column names to lowercase\n",
    "    df_selected.columns = [col.lower() for col in df_selected.columns]\n",
    "\n",
    "    # Convert column types (converting 'population' to int)\n",
    "    df_selected['population'] = df_selected['population'].astype(int)\n",
    "    \n",
    "    # drop duplicate zipcodes\n",
    "    df_selected = df_selected.drop_duplicates(subset='zipcode')\n",
    "    \n",
    "    # Change the SRID to a specific value (EPSG 4326 - WGS 84)\n",
    "    df_selected = df_selected.to_crs(epsg=4326)\n",
    "    \n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d746d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    start_date = \"2015-01-01T00:00:00.000\"\n",
    "    end_date = \"2023-09-30T23:59:59.000\"\n",
    "\n",
    "    url = (\n",
    "        f\"{BASE_NYC_DATA_URL}{NYC_DATA_311}?\"\n",
    "        f\"$$app_token={NYC_DATA_APP_TOKEN}&\"\n",
    "        f\"$where=created_date between '{start_date}' and '{end_date}'&\"\n",
    "        f\"$limit=1000000\"\n",
    "    )\n",
    "    \n",
    "    filename = download_nyc_geojson_data(url)\n",
    "    df=gpd.read_file(filename)\n",
    "    \n",
    "    # To keep the necessary columns\n",
    "    df_selected=df[['unique_key', 'created_date','city','incident_zip','complaint_type','geometry']]\n",
    "\n",
    "    # Drop rows with missing values---we find that if drop all na, it will delete all the data.\n",
    "    df_selected=df_selected.dropna()\n",
    "    \n",
    "    # Convert column names to lowercase\n",
    "    df_selected.columns = [col.lower() for col in df_selected.columns]\n",
    "    \n",
    "    # Change the SRID to a specific value (EPSG 4326 - WGS 84)\n",
    "    df_selected['geometry'] = df_selected['geometry'].to_crs(epsg=4326)\n",
    "    \n",
    "    \n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd44dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    url=f\"{BASE_NYC_DATA_URL}{NYC_DATA_TREES}?$$app_token={NYC_DATA_APP_TOKEN}&$limit=700000\"\n",
    "    filename=download_nyc_geojson_data(url)\n",
    "    df=gpd.read_file(filename)\n",
    "    \n",
    "    # To keep the necessary columns\n",
    "    df_selected=df[['tree_id','zipcode','address','health','zip_city','spc_common','status','sidewalk','borocode','block_id','geometry']]\n",
    "    \n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    df_selected=df_selected.dropna()\n",
    "    \n",
    "    # Convert column names to lowercase\n",
    "    df_selected.columns = [col.lower() for col in df_selected.columns]\n",
    "    \n",
    "    # Change the SRID to a specific value (EPSG 4326 - WGS 84)\n",
    "    df_selected = df_selected.to_crs(epsg=4326)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0bd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data():\n",
    "    \"\"\"\n",
    "    Load and clean Zillow data from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The file path to the Zillow data CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned DataFrame containing Zillow data.\n",
    "    \"\"\"\n",
    "    # Load the data from the CSV file\n",
    "    zillow_data = pd.read_csv(ZILLOW_DATA_FILE)\n",
    "\n",
    "    # To keep the necessary columns\n",
    "    zillow_selected = zillow_data\n",
    "    \n",
    "    # only keep data in NY\n",
    "    zillow_selected = zillow_selected[zillow_selected['State'] == 'NY']\n",
    "    zillow_selected = zillow_selected.dropna()\n",
    "    \n",
    "    return zillow_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637e3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
